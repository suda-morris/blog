(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{337:function(s,t,a){s.exports=a.p+"assets/img/linear_regression.d67e8d49.png"},338:function(s,t,a){s.exports=a.p+"assets/img/nonlinear_regression.f58b96b1.png"},535:function(s,t,a){"use strict";a.r(t);var n=a(12),r=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"keras-基础"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#keras-基础"}},[s._v("#")]),s._v(" 𝙆𝙚𝙧𝙖𝙨 基础")]),s._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("参考文档")]),s._v(" "),t("p",[t("a",{attrs:{href:"https://keras.io",target:"_blank",rel:"noopener noreferrer"}},[s._v("Keras 官网文档"),t("OutboundLink")],1)])]),s._v(" "),t("h2",{attrs:{id:"安装"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#安装"}},[s._v("#")]),s._v(" 安装")]),s._v(" "),t("div",{staticClass:"language-bash line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-bash"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 安装 Tensorflow")]),s._v("\npip "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" tensorflow --user -i https://pypi.tuna.tsinghua.edu.cn/simple\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 安装 Keras")]),s._v("\npip "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("install")]),s._v(" keras --user -i https://pypi.tuna.tsinghua.edu.cn/simple\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br")])]),t("h2",{attrs:{id:"线性回归"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#线性回归"}},[s._v("#")]),s._v(" 线性回归")]),s._v(" "),t("h3",{attrs:{id:"示例程序"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#示例程序"}},[s._v("#")]),s._v(" 示例程序")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -*- coding:utf-8 -*-")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" keras\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Sequential  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Keras 中的顺序模型")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("layers "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Dense  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Keras 中的全连接层")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 构造训练样本")]),s._v("\nx_train "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rand"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 一维数据，样本量 100，服从均一分布")]),s._v("\nnoise "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("normal"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.01")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 噪声数据，服从高斯分布（正态分布）")]),s._v("\ny_train "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x_train"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" noise\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 编译模型")]),s._v("\nmodel "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Sequential"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 顺序模型")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层，输出数据 1 维， 输入数据 1 维")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("compile")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("optimizer"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"sgd"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" loss"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"mse"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 优化算法：随机梯度下降，损失函数：均方差")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 训练样本")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" step "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    cost "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train_on_batch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" step "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("500")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cost: "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" cost"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查看训练得到的权重和偏置")]),s._v("\nw"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" b "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("layers"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("get_weights"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"W= "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" w"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"b= "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" b"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 展示拟合结果")]),s._v("\ny_pred "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("predict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scatter"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_pred"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"r-"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lw"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br")])]),t("h3",{attrs:{id:"结果展示"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#结果展示"}},[s._v("#")]),s._v(" 结果展示")]),s._v(" "),t("p",[t("img",{attrs:{src:a(337),alt:"linear_regression"}})]),s._v(" "),t("h2",{attrs:{id:"非线性回归"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#非线性回归"}},[s._v("#")]),s._v(" 非线性回归")]),s._v(" "),t("h3",{attrs:{id:"示例程序-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#示例程序-2"}},[s._v("#")]),s._v(" 示例程序")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -*- coding:utf-8 -*-")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" matplotlib"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("pyplot "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" plt\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" keras\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Sequential  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Keras 中的顺序模型")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("layers "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Dense"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Activation  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Keras 中的全连接层和激活函数")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("optimizers "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" SGD  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# Keras 中的 SGD 优化器")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 构造训练样本")]),s._v("\nx_train "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("linspace"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("200")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 一维数据，样本量 200，等差线性分布")]),s._v("\nnoise "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("normal"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.02")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 噪声数据，服从高斯分布（正态分布）")]),s._v("\ny_train "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("square"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" noise\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 编译模型")]),s._v("\nmodel "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Sequential"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 顺序模型")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层，输出数据 10 维， 输入数据 1 维")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Activation"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tanh"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tanh 激活函数")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层，输出数据 1 维， 输入数据 10 维")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Activation"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tanh"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# tanh 激活函数")]),s._v("\nsgd "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" SGD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lr"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 设置随机梯度下降算法的学习率")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("compile")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("optimizer"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("sgd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" loss"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"mse"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 优化算法：随机梯度下降，损失函数：均方差")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 训练样本")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" step "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("range")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5000")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    cost "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("train_on_batch"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" step "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("%")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("500")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"cost: "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" cost"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 展示拟合结果")]),s._v("\ny_pred "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("predict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("scatter"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("plot"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_pred"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"r-"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" lw"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nplt"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("show"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br")])]),t("h3",{attrs:{id:"结果展示-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#结果展示-2"}},[s._v("#")]),s._v(" 结果展示")]),s._v(" "),t("p",[t("img",{attrs:{src:a(338),alt:"nonlinear_regression"}})]),s._v(" "),t("h2",{attrs:{id:"mnist-数据分类"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#mnist-数据分类"}},[s._v("#")]),s._v(" MNIST 数据分类")]),s._v(" "),t("h3",{attrs:{id:"示例程序-3"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#示例程序-3"}},[s._v("#")]),s._v(" 示例程序")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# -*- coding:utf-8 -*-")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" keras\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("datasets "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" mnist\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("utils "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" np_utils\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("models "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Sequential\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("layers "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" Dense"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Activation"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" Dropout\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" keras"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("optimizers "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" SGD\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 载入数据集（第一次运行会联网下载）")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" mnist"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("load_data"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"x_train: "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"y_train: "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"x_test:  "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" x_test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"y_test:  "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nx_train "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("255.0")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 归一化")]),s._v("\nx_test "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" x_test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("reshape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("/")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("255.0")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 标签值转为 one-hot 码")]),s._v("\ny_train "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np_utils"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to_categorical"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_classes"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ny_test "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np_utils"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to_categorical"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("y_test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" num_classes"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 编译模型")]),s._v("\nmodel "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" Sequential"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 顺序模型")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层(隐藏层），输出数据 200 维，输入数据维度由训练数据本身决定, 使用 tanh 激活函数")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("200")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" input_dim"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" activation"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tanh"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dropout"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 让 40% 的神经元不工作（防止过拟合的一种手段）")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层（隐藏层），输出数据 100 维，输入数据由前一层决定, 使用 tanh 激活函数")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" activation"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"tanh"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dropout"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 让 40% 的神经元不工作（防止过拟合的一种手段）")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 全连接层（输出层），输出数据 10 维（共 10 种手写数字），输入数据由前一层决定, 使用 softmax 激活函数")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("add"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("Dense"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("units"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" activation"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"softmax"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nsgd "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" SGD"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("lr"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 设置随机梯度下降算法的学习率")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("compile")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("optimizer"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("sgd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" loss"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"categorical_crossentropy"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" metrics"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("\n              "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"accuracy"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 优化算法：随机梯度下降，损失函数：交叉熵")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 训练样本")]),s._v("\nmodel"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_train"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" batch_size"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("32")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" epochs"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 评估模型")]),s._v("\nloss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" accuracy "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" model"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("evaluate"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("x_test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" y_test"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"loss= "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" loss"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"accuracy= "')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" accuracy"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br")])])])}),[],!1,null,null,null);t.default=r.exports}}]);