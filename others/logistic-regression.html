<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>suda-morris ä¸ªäººåšå®¢</title>
    <meta name="description" content="è®°å½•å­¦ä¹ ç”Ÿæ´»ï¼Œæ¢ç´¢æœªçŸ¥é¢†åŸŸ">
    <link rel="icon" href="/blog/favicon.png">
  <link rel="manifest" href="/blog/manifest.json">
    
    <link rel="preload" href="/blog/assets/css/0.styles.aea52b3d.css" as="style"><link rel="preload" href="/blog/assets/js/app.dc011b77.js" as="script"><link rel="preload" href="/blog/assets/js/2.4a73e09d.js" as="script"><link rel="preload" href="/blog/assets/js/41.c49f0714.js" as="script"><link rel="preload" href="/blog/assets/js/3.b11672f7.js" as="script"><link rel="prefetch" href="/blog/assets/js/10.53d33d2d.js"><link rel="prefetch" href="/blog/assets/js/11.a452eadb.js"><link rel="prefetch" href="/blog/assets/js/12.eafb2f27.js"><link rel="prefetch" href="/blog/assets/js/13.94c505d0.js"><link rel="prefetch" href="/blog/assets/js/14.d59211b4.js"><link rel="prefetch" href="/blog/assets/js/15.2e8fafc4.js"><link rel="prefetch" href="/blog/assets/js/16.14c13aa7.js"><link rel="prefetch" href="/blog/assets/js/17.0ee49138.js"><link rel="prefetch" href="/blog/assets/js/18.49c51782.js"><link rel="prefetch" href="/blog/assets/js/19.26f0abbb.js"><link rel="prefetch" href="/blog/assets/js/20.5d20b12e.js"><link rel="prefetch" href="/blog/assets/js/21.dad5174f.js"><link rel="prefetch" href="/blog/assets/js/22.1d1b0861.js"><link rel="prefetch" href="/blog/assets/js/23.418d6234.js"><link rel="prefetch" href="/blog/assets/js/24.b2f0fb97.js"><link rel="prefetch" href="/blog/assets/js/25.2e67b9a1.js"><link rel="prefetch" href="/blog/assets/js/26.34d6247d.js"><link rel="prefetch" href="/blog/assets/js/27.0b0ef00c.js"><link rel="prefetch" href="/blog/assets/js/28.59f1bd9e.js"><link rel="prefetch" href="/blog/assets/js/29.af6fa38e.js"><link rel="prefetch" href="/blog/assets/js/30.89bb07b1.js"><link rel="prefetch" href="/blog/assets/js/31.6c694c6a.js"><link rel="prefetch" href="/blog/assets/js/32.6f5dab1a.js"><link rel="prefetch" href="/blog/assets/js/33.08d00d32.js"><link rel="prefetch" href="/blog/assets/js/34.ba4bf389.js"><link rel="prefetch" href="/blog/assets/js/35.b5009de5.js"><link rel="prefetch" href="/blog/assets/js/36.e42233c4.js"><link rel="prefetch" href="/blog/assets/js/37.96b284de.js"><link rel="prefetch" href="/blog/assets/js/38.a7eda2dc.js"><link rel="prefetch" href="/blog/assets/js/39.0a11c877.js"><link rel="prefetch" href="/blog/assets/js/4.e3e090f7.js"><link rel="prefetch" href="/blog/assets/js/40.dab93db9.js"><link rel="prefetch" href="/blog/assets/js/42.d8d152e7.js"><link rel="prefetch" href="/blog/assets/js/43.c3053021.js"><link rel="prefetch" href="/blog/assets/js/44.30cf0529.js"><link rel="prefetch" href="/blog/assets/js/45.9220b443.js"><link rel="prefetch" href="/blog/assets/js/46.547cb6b8.js"><link rel="prefetch" href="/blog/assets/js/47.778b8037.js"><link rel="prefetch" href="/blog/assets/js/48.fc41c802.js"><link rel="prefetch" href="/blog/assets/js/49.aac13fd5.js"><link rel="prefetch" href="/blog/assets/js/5.2a354d3d.js"><link rel="prefetch" href="/blog/assets/js/50.de6cb49e.js"><link rel="prefetch" href="/blog/assets/js/51.7af9f517.js"><link rel="prefetch" href="/blog/assets/js/52.bfc474a5.js"><link rel="prefetch" href="/blog/assets/js/53.84a3e79e.js"><link rel="prefetch" href="/blog/assets/js/54.c36819a0.js"><link rel="prefetch" href="/blog/assets/js/55.69dcb2f2.js"><link rel="prefetch" href="/blog/assets/js/56.f020f43e.js"><link rel="prefetch" href="/blog/assets/js/57.8f3b4900.js"><link rel="prefetch" href="/blog/assets/js/58.8701bd1e.js"><link rel="prefetch" href="/blog/assets/js/59.e91c2df4.js"><link rel="prefetch" href="/blog/assets/js/6.a0364a73.js"><link rel="prefetch" href="/blog/assets/js/60.80dc3e63.js"><link rel="prefetch" href="/blog/assets/js/61.bc8d93c4.js"><link rel="prefetch" href="/blog/assets/js/62.4935f44a.js"><link rel="prefetch" href="/blog/assets/js/63.ab69d6e9.js"><link rel="prefetch" href="/blog/assets/js/64.d1675061.js"><link rel="prefetch" href="/blog/assets/js/65.47f1a366.js"><link rel="prefetch" href="/blog/assets/js/66.631e6987.js"><link rel="prefetch" href="/blog/assets/js/67.deda1286.js"><link rel="prefetch" href="/blog/assets/js/68.d488748b.js"><link rel="prefetch" href="/blog/assets/js/69.4084b8dc.js"><link rel="prefetch" href="/blog/assets/js/7.05f8ac37.js"><link rel="prefetch" href="/blog/assets/js/70.5a644ac8.js"><link rel="prefetch" href="/blog/assets/js/71.75c2f594.js"><link rel="prefetch" href="/blog/assets/js/8.ab17c590.js"><link rel="prefetch" href="/blog/assets/js/9.5709aa1f.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.aea52b3d.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blog/" class="home-link router-link-active"><!----> <span class="site-name">suda-morris ä¸ªäººåšå®¢</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/" class="nav-link">Home</a></div><div class="nav-item"><a href="/blog/cs/" class="nav-link">CS</a></div><div class="nav-item"><a href="/blog/ee/" class="nav-link">EE</a></div><div class="nav-item"><a href="/blog/others/" class="nav-link router-link-active">Others</a></div> <a href="https://github.com/suda-morris/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/blog/" class="nav-link">Home</a></div><div class="nav-item"><a href="/blog/cs/" class="nav-link">CS</a></div><div class="nav-item"><a href="/blog/ee/" class="nav-link">EE</a></div><div class="nav-item"><a href="/blog/others/" class="nav-link router-link-active">Others</a></div> <a href="https://github.com/suda-morris/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><a href="/blog/others/about.html" class="sidebar-link">å…³äºæœ¬æ ç›®</a></li><li><a href="/blog/others/markdown.html" class="sidebar-link">Markdown åŸºæœ¬è¯­æ³• ğŸ‰ ğŸ’¯</a></li></ul> </aside> <main class="page"> <div class="content default"><p>title: Logistic Regression
tags:</p> <ul><li>Logistic
categories:</li> <li>AI
author: suda-morris
date: 2018-10-15 12:36:12 +0800</li></ul> <hr> <h1 id="logistic-regression"><a href="#logistic-regression" aria-hidden="true" class="header-anchor">#</a> Logistic Regression</h1> <blockquote><ol><li>Logisticå›å½’è™½ç„¶æ˜¯åå­—ä¸­å¸¦æœ‰â€œå›å½’â€ï¼Œä½†å®é™…ä¸Šå®ƒæ˜¯ä¸€ç§<strong>åˆ†ç±»ç®—æ³•</strong>ï¼Œä¸»è¦åº”ç”¨ä¸<strong>äºŒåˆ†ç±»</strong>é—®é¢˜(è¾“å‡ºåªæœ‰ä¸¤ç§ç»“æœï¼Œæ¯”å¦‚0å’Œ1)</li> <li>é€»è¾‘å›å½’å®è´¨ä¸Šå¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§ç®€å•çš„<strong>ç¥ç»ç½‘ç»œ</strong></li></ol></blockquote> <p><img src="https://s1.ax1x.com/2018/10/15/ialgpR.png" alt="LogReg_kiank"></p> <h2 id="æ•°å­¦å…¬å¼æ¨å¯¼"><a href="#æ•°å­¦å…¬å¼æ¨å¯¼" aria-hidden="true" class="header-anchor">#</a> æ•°å­¦å…¬å¼æ¨å¯¼</h2> <p>å‡è®¾ç¥ç»å…ƒçš„çªè§¦çš„æƒé‡å‘é‡ä¸º<strong>w</strong>ï¼Œçº¿æ€§åç½®ä¸º<strong>b</strong>(æ ‡é‡)ï¼Œå¯¹äºç¬¬iä¸ªæ ·æœ¬$x^{(i)}$æ¥è¯´ï¼š</p> <p>$$z^{(i)} = w^T x^{(i)} + b\tag{1}$$</p> <p>å¾—åˆ°çš„$z^{(i)}$éœ€è¦è¿›ä¸€æ­¥è¾“å…¥æ¿€æ´»å‡½æ•°ï¼Œæ¿€æ´»å‡½æ•°çš„é€‰æ‹©æœ‰å¾ˆå¤šç§ï¼Œè€ƒè™‘åˆ°Logisticå›å½’çš„è¾“å‡ºåªæœ‰0å’Œ1ä¸¤ç§æƒ…å†µï¼Œå› æ­¤é€‰ç”¨sigmoidå‡½æ•°ä¼šæ¯”è¾ƒç¬¦åˆè¦æ±‚ï¼š</p> <p>$$\hat{y}^{(i)}=a^{(i)}=sigmoid(z^{(i)})\tag{2}$$</p> <p>sigmoidå‡½æ•°çš„å¯¼æ•°ï¼š</p> <p>$$\frac{da}{dz}=a(1-a)\tag{3}$$</p> <p><img src="https://s1.ax1x.com/2018/10/15/ialR6x.png" alt="Sigmoid"></p> <p>å¦‚ä½•è¡¡é‡é¢„æµ‹ç»“æœçš„å¥½åï¼Œéœ€è¦å®šä¹‰æŸå¤±å‡½æ•°<strong>L</strong>ï¼š</p> <p>$$ L(a^{(i)},y^{(i)})=- y^{(i)}\ln(a^{(i)})-(1-y^{(i)})\ln(1-a^{(i)})\tag{4}$$</p> <p>é‚£ä¹ˆä»·å€¼å‡½æ•°<strong>J</strong>å°±æ˜¯æ‰€æœ‰æ ·æœ¬çš„æŸå¤±å€¼çš„å¹³å‡ï¼š</p> <p>$$ J=\frac{1}{m}\sum_{i=1}^mL(a^{(i)}, y^{(i)})\tag{5}$$</p> <p>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€šè¿‡å¤šæ¬¡çš„è¿­ä»£ï¼Œæ±‚å¾—ä½¿å¾—<strong>J</strong>æœ€å°çš„è‡ªå˜é‡å‚æ•°wå’Œbï¼Œè¿™é‡Œä½¿ç”¨çš„ä¼˜åŒ–ç®—æ³•ä¸ºæ¢¯åº¦ä¸‹é™æ³•ï¼Œå…¶ä¸­Î±ç§°ä¸ºå­¦ä¹ ç‡ï¼Œæ˜¯0~1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼š</p> <p>$$\theta=\theta-\alpha d\theta\tag{6}$$</p> <p>æˆ‘ä»¬æŠŠæ±‚è§£ä»·å€¼å‡½æ•°çš„è¿‡ç¨‹ç§°ä¸º<strong>æ­£å‘ä¼ æ’­</strong>ï¼ŒæŠŠæ±‚è§£æ¢¯åº¦çš„è¿‡ç¨‹ç§°ä¸º<strong>åå‘ä¼ æ’­</strong></p> <p>ä»·å€¼å‡½æ•°å¯¹äºç¬¬jä¸ªçªè§¦$w_j$çš„æ¢¯åº¦ï¼š
$$
\frac{\partial J}{\partial w_j}=\frac{1}{m}\sum_{i=1}^m\frac{\partial}{\partial w_j}[-y^{(i)}\ln{(a^{(i)})}-(1-y^{(i)})\ln{(1-a^{(i)})}]\
=\frac{1}{m}\sum_{i=1}^{m}[\frac{-y^{(i)}}{a^{(i)}}\cdot\frac{\partial{a^{(i)}}}{\partial{w_j}}+\frac{(1-y^{i})}{1-a^{(i)}}\cdot\frac{\partial{a^{i}}}{\partial{w_j}}]\
=\frac{1}{m}\sum_{i=1}^{m}[\frac{\partial{a^{(i)}}}{\partial{w_j}}\cdot(\frac{1-y^{(i)}}{1-a^{(i)}}-\frac{y^{(i)}}{a^{(i)}})]\
=\frac{1}{m}\sum_{i=1}^{m}[\frac{d{a^{(i)}}}{d{z^{(i)}}}\cdot\frac{\partial{z^{(i)}}}{\partial{w_j}}\cdot(\frac{1-y^{(i)}}{1-a^{(i)}}-\frac{y^{(i)}}{a^{(i)}})]\
=\frac{1}{m}\sum_{i=1}^{m}[a^{(i)}\cdot(1-a^{(i)})\cdot x_j^{(i)}\cdot\frac{a^{(i)}-y^{(i)}}{a^{(i)}\cdot(1-a^{(i)})}]\
=\frac{1}{m}\sum_{i=1}^{m}[x_j^{(i)}\cdot(a^{(i)}-y^{(i)})]
$$
ä»·å€¼å‡½æ•°<strong>J</strong>å¯¹äºæ‰€æœ‰çªè§¦çš„æƒé‡å‘é‡<strong>w</strong>çš„æ¢¯åº¦ï¼š</p> <p>$$ \frac{\partial J}{\partial w}=\frac{1}{m}X(A-Y)^T\tag{7}$$</p> <p>ä»·å€¼å‡½æ•°<strong>J</strong>å¯¹åç½®<strong>b</strong>çš„æ¢¯åº¦ï¼š</p> <p>$$ \frac{\partial J}{\partial b}=\frac{1}{m}\sum_{i=1}^m (a^{(i)}-y^{(i)})\tag{8}$$</p> <p>æ‰€ä»¥ï¼Œæ¯ä¸€æ¬¡è¿­ä»£çš„è¿‡ç¨‹ä¸­ï¼Œå¯¹wå’Œbçš„<strong>æ›´æ–°è§„åˆ™</strong>ä¸ºï¼š</p> <p>$$w:=w-\alpha\frac{\partial{J}}{\partial{w}}\tag{9}$$</p> <p>$$b:=b-\alpha\frac{\partial{J}}{\partial{b}}\tag{10}$$</p> <h2 id="pythonç¨‹åºç¼–å†™"><a href="#pythonç¨‹åºç¼–å†™" aria-hidden="true" class="header-anchor">#</a> Pythonç¨‹åºç¼–å†™</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd


<span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot;
    Compute the sigmoid of z
    :param z: A scalar or numpy array of any size.
    :return: sigmoid(z)
    &quot;&quot;&quot;</span>
    s <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span> <span class="token operator">*</span> z<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> s


<span class="token keyword">class</span> <span class="token class-name">LogisticRegression</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_iterations<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> print_cost<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Builds the logistic regression model
        :param num_iterations: hyperparameter representing the number of iterations to optimize the parameters
        :param learning_rate: hyperparameter representing the learning rate when update the parameters
        :param print_cost: Set to true to print the cost every 100 iterations
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>n_iter <span class="token operator">=</span> num_iterations
        self<span class="token punctuation">.</span>learn_rate <span class="token operator">=</span> learning_rate
        self<span class="token punctuation">.</span>print_cost <span class="token operator">=</span> print_cost
        self<span class="token punctuation">.</span>w <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># weights, a numpy array of size</span>
        self<span class="token punctuation">.</span>b <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># bias, a scalar</span>

    <span class="token keyword">def</span> <span class="token function">__initialize_with_zeros</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.
        :param dim: size of the w vector we want
        :return: w -- initialized vector of shape (dim, 1); b -- initialized scalar (corresponds to the bias)
        &quot;&quot;&quot;</span>
        w <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        b <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>w<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span>dim<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span><span class="token builtin">isinstance</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>b<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> w<span class="token punctuation">,</span> b

    <span class="token keyword">def</span> <span class="token function">__propagate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Implement the cost function and its gradient for the propagation
        :param X: input data
        :param Y: label vector
        :return: grads --- results of backward propagation; cost --- results of forward propagation
        &quot;&quot;&quot;</span>
        m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token comment"># FORWARD PROPAGATION (FROM X TO COST)</span>
        Z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>T<span class="token punctuation">,</span> X<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b
        A <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>Z<span class="token punctuation">)</span>  <span class="token comment"># compute activation</span>
        cost <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> Y<span class="token punctuation">,</span> np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> A<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># compute cost</span>

        <span class="token comment"># BACKWARD PROPAGATION (TO FIND GRAD)</span>
        dw <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> m <span class="token operator">*</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token punctuation">(</span>A <span class="token operator">-</span> Y<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># gradient of the loss with respect to w, thus same shape as w</span>
        db <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>A <span class="token operator">-</span> Y<span class="token punctuation">)</span> <span class="token operator">/</span> m  <span class="token comment"># gradient of the loss with respect to b, thus same shape as b</span>

        <span class="token keyword">assert</span> <span class="token punctuation">(</span>dw<span class="token punctuation">.</span>shape <span class="token operator">==</span> self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>db<span class="token punctuation">.</span>dtype <span class="token operator">==</span> <span class="token builtin">float</span><span class="token punctuation">)</span>
        cost <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>cost<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        grads <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;dw&quot;</span><span class="token punctuation">:</span> dw<span class="token punctuation">,</span>
                 <span class="token string">&quot;db&quot;</span><span class="token punctuation">:</span> db<span class="token punctuation">}</span>
        <span class="token keyword">return</span> grads<span class="token punctuation">,</span> cost

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        This function optimizes w and b by running a gradient descent algorithm
        :param X_train: input data
        :param Y_train: label vector
        :return: costs -- list of all the costs computed during the optimization
        &quot;&quot;&quot;</span>
        <span class="token comment"># initialize parameters with zeros</span>
        self<span class="token punctuation">.</span>w<span class="token punctuation">,</span> self<span class="token punctuation">.</span>b <span class="token operator">=</span> self<span class="token punctuation">.</span>__initialize_with_zeros<span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        costs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>
            grads<span class="token punctuation">,</span> cost <span class="token operator">=</span> self<span class="token punctuation">.</span>__propagate<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span>  <span class="token comment"># Cost and gradient calculation</span>
            dw <span class="token operator">=</span> grads<span class="token punctuation">[</span><span class="token string">&quot;dw&quot;</span><span class="token punctuation">]</span>
            db <span class="token operator">=</span> grads<span class="token punctuation">[</span><span class="token string">&quot;db&quot;</span><span class="token punctuation">]</span>
            <span class="token comment"># update rule</span>
            self<span class="token punctuation">.</span>w <span class="token operator">-=</span> self<span class="token punctuation">.</span>learn_rate <span class="token operator">*</span> dw
            self<span class="token punctuation">.</span>b <span class="token operator">-=</span> self<span class="token punctuation">.</span>learn_rate <span class="token operator">*</span> db
            <span class="token comment"># Record the costs</span>
            <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                costs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>
            <span class="token comment"># Print the cost every 100 training examples</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>print_cost <span class="token keyword">and</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;Cost after iteration %i: %f&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i<span class="token punctuation">,</span> cost<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> costs

    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X_test<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)
        :param X_test: input data
        :return: Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X_test
        &quot;&quot;&quot;</span>
        m <span class="token operator">=</span> X_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        Y_prediction <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> m<span class="token punctuation">)</span><span class="token punctuation">)</span>
        w <span class="token operator">=</span> self<span class="token punctuation">.</span>w<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># Compute vector &quot;A&quot; predicting the probabilities</span>
        A <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">.</span>T<span class="token punctuation">,</span> X_test<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b<span class="token punctuation">)</span>
        <span class="token comment"># Convert probabilities A[0,i] to actual predictions p[0,i]</span>
        Y_prediction <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>A <span class="token operator">&gt;</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span>Y_prediction<span class="token punctuation">.</span>shape <span class="token operator">==</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> m<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> Y_prediction


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&quot;__main__&quot;</span><span class="token punctuation">:</span>
    train_size <span class="token operator">=</span> <span class="token number">150</span>
    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&quot;iris.csv&quot;</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    Y_train <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>train_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values
    Y_train <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>Y_train <span class="token operator">==</span> <span class="token string">&quot;Iris-setosa&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    Y_train <span class="token operator">=</span> Y_train<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> train_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    X_train <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>train_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values
    feature1_min<span class="token punctuation">,</span> feature1_max <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    feature2_min<span class="token punctuation">,</span> feature2_max <span class="token operator">=</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    X_train <span class="token operator">=</span> X_train<span class="token punctuation">.</span>T<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> train_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    clf <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>num_iterations<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> print_cost<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> Y_train<span class="token punctuation">)</span>

    <span class="token comment"># å°†å‘é‡æ‰©å……ä¸ºäºŒç»´çŸ©é˜µï¼Œä½œä¸ºæµ‹è¯•æ ·æœ¬</span>
    xx1<span class="token punctuation">,</span> xx2 <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>feature1_min<span class="token punctuation">,</span> feature1_max<span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>feature2_min<span class="token punctuation">,</span> feature2_max<span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    X_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>xx1<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx2<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># é¢„æµ‹ç»“æœ</span>
    Y_prediction <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
    Y_prediction <span class="token operator">=</span> Y_prediction<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token comment"># æ•°æ®å¯è§†åŒ–</span>
    markers <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">)</span>
    colors <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">&quot;red&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;blue&quot;</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx1<span class="token punctuation">,</span> xx2<span class="token punctuation">,</span> Y_prediction<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">&quot;gray&quot;</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span>feature1_min<span class="token punctuation">,</span> feature1_max<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span>feature2_min<span class="token punctuation">,</span> feature2_max<span class="token punctuation">)</span>
    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> y_train <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>Y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>Y_train <span class="token operator">==</span> y_train<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>Y_train <span class="token operator">==</span> y_train<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                    alpha<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> c<span class="token operator">=</span>colors<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span>
                    marker<span class="token operator">=</span>markers<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>y_train<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">u&quot;èŠ±ç“£é•¿åº¦&quot;</span><span class="token punctuation">,</span> fontproperties<span class="token operator">=</span><span class="token string">'SimHei'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">u&quot;èŠ±èŒé•¿åº¦&quot;</span><span class="token punctuation">,</span> fontproperties<span class="token operator">=</span><span class="token string">'SimHei'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">&quot;upper left&quot;</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br><span class="line-number">106</span><br><span class="line-number">107</span><br><span class="line-number">108</span><br><span class="line-number">109</span><br><span class="line-number">110</span><br><span class="line-number">111</span><br><span class="line-number">112</span><br><span class="line-number">113</span><br><span class="line-number">114</span><br><span class="line-number">115</span><br><span class="line-number">116</span><br><span class="line-number">117</span><br><span class="line-number">118</span><br><span class="line-number">119</span><br><span class="line-number">120</span><br><span class="line-number">121</span><br><span class="line-number">122</span><br><span class="line-number">123</span><br><span class="line-number">124</span><br><span class="line-number">125</span><br><span class="line-number">126</span><br><span class="line-number">127</span><br><span class="line-number">128</span><br><span class="line-number">129</span><br><span class="line-number">130</span><br><span class="line-number">131</span><br><span class="line-number">132</span><br><span class="line-number">133</span><br><span class="line-number">134</span><br><span class="line-number">135</span><br><span class="line-number">136</span><br><span class="line-number">137</span><br><span class="line-number">138</span><br><span class="line-number">139</span><br><span class="line-number">140</span><br><span class="line-number">141</span><br><span class="line-number">142</span><br><span class="line-number">143</span><br><span class="line-number">144</span><br><span class="line-number">145</span><br></div></div></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/suda-morris/blog/edit/master/docs/others/logistic-regression.md" target="_blank" rel="noopener noreferrer">ç¼–è¾‘æ­¤é¡µé¢</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <div class="last-updated"><span class="prefix">ä¸Šæ¬¡æ›´æ–°: </span> <span class="time">5/4/2019, 6:39:29 AM</span></div></footer> <!----> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/blog/assets/js/app.dc011b77.js" defer></script><script src="/blog/assets/js/2.4a73e09d.js" defer></script><script src="/blog/assets/js/41.c49f0714.js" defer></script><script src="/blog/assets/js/3.b11672f7.js" defer></script>
  </body>
</html>
